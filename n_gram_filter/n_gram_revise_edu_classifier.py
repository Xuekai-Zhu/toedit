from transformers import AutoTokenizer, AutoModelForSequenceClassification
from n_gram_filter import load_object_from_file
from nltk import word_tokenize
import numpy as np

def softmax(x):
    e_x = np.exp(x - np.max(x))  # 减去最大值以稳定数值计算
    return e_x / e_x.sum(axis=0)

def reject_sampling(possible_words_sorted, candicate_num=64, num_samples=1, beta=0.1):
    candidates = {w: prob_dist.prob(w) for w in possible_words_sorted[:candicate_num]}
    
    rewards = np.array(list(candidates.values()))
    adjusted_probs = softmax(rewards / beta)  # 调整温度
    
    accepted = []
    while len(accepted) < num_samples:
        # max_reward = max(candidates.values())  # 获取最大概率（最高奖励）
        to_remove = []
        
        for idx, (candidate, reward) in enumerate(candidates.items()):
            u = np.random.uniform()  # 生成一个0到1之间的随机数
            if u >= adjusted_probs[idx]:  # 使用 softmax 概率
                continue
        
        # for c, r in candidates.items():
        #     u = np.random.uniform()  # 生成一个0到1之间的随机数
        #     here = (r - max_reward) / beta
        #     # here_exp = np.exp((r - max_reward) / beta)
        #     if u >= here:  # 根据计算的接受概率决定是否接受
        #         continue
            accepted.append(candidate)  # 接受词
            to_remove.append(candidate)  # 记录已处理的词

            if len(accepted) == num_samples:  # 如果达到所需样本数量，停止采样
                break
        
        # 从候选集中移除已处理的词
        for c in to_remove:
            candidates.pop(c)

    return accepted
    

threshold = 0.000001
text = "[Opening speech of the Congress President of the German Society for Pathology].\n\nGenerate your own set of questions and answers about the above article:\n****\n[Ques]: what is the congress president of the german society for?\n[Ans]: Here's my solution: [Opening speech of the Congress President of the German Society for Pathology]. The answer is Pathology\n\nInhibition of factor IXa and factor Xa by antithrombin III/heparin during factor X activation.\nWe investigated the kinetics of the inhibitory action of antithrombin III and antithrombin III plus heparin during the activation of factor X by factor IXa. Generation and inactivation curves were fitted to a three-parameter two-exponentional model to determine the pseudo first-order rate constants of inhibition of factor IXa and factor Xa by antithrombin III/heparin. In the absence of heparin, the second-order rate constant of inhibition of factor Xa generated by factor IXa was 2.5-fold lower than the rate constant of inhibition of exogenous factor Xa. It appeared that phospholipid-bound factor X protected factor Xa from inactivation by antithrombin III. It is, as yet, unclear whether an active site or a nonactive site interaction between factor Xa and factor X at the phospholipid surface is involved. The inactivation of factor IXa by antithrombin III was found to be very slow and was not affected by phospholipid, calcium, and/or factor X. With unfractionated heparin above 40 ng/ml and antithrombin III at 200 nM, the apparent second-order rate constant of inhibition of exogenous and generated factor Xa were the same. Thus, in this case phospholipid-bound factor X did not protect factor Xa from inhibition. In the presence of synthetic pentasaccharide heparin, however, phospholipid-bound factor X reduced the rate constant about 5-fold. Pentasaccharide had no effect on the factor IXa/antithrombin III reaction. Unfractionated heparin (1 micrograms/ml) stimulated the antithrombin III-dependent inhibition of factor IXa during factor X activation 400-fold. In the absence of reaction components this stimulated was 65-fold. We established that calcium stimulated the heparin-dependent inhibition of factor IXa.\nGenerate your own set of questions and answers about the above article:\n****\n[Ques]: does the pentasaccharide heparin reduce the inhibitory effect of antithrombin III on factor X activation?\n[Ans]: Here's my solution: The inhibitory effect of antithrombin III on factor X activation can be reduced by a factor of approximately 5 when the reaction is performed in the presence of synthetic pentasaccharide heparin. This effect is independent of the concentration of calcium present. We propose that the reduction in inhibitory effect is due to a change in the conformation of factor Xa upon binding to the phospholipid surface, which allows the factor Xa active site to be directed toward the inhibitory peptide bond of antithrombin III. The answer is Yes\n\n[Molecular imaging of beta-amyloid plaques in the brain].\nAlzheimer's disease (AD) is a neurodegenerative disease characterized by dementia, cognitive impairment, and memory loss. Postmortem brains of AD patients reveal neuropathological features; the presence of beta-amyloid plaques and neurofibrillary tangles, which contain beta-amyloid peptides (Abeta) and highly phosphorylated tau proteins. Increases in the concentration of Abeta in the course of the disease lead to gradual increase in the load of beta-amyloid plaques, which is thought to be an initial neuropathological change in AD brains. Thus, the development of radiotracers for in vivo imaging beta-amyloid plaques in the aging human brain is an important and active area of molecular imaging. When used in combination with positron emission tomography (PET) or single photon emission computed tomography (SPECT), amyloid imaging agents could serve as surrogate markers in early diagnosis and neuropathogenesis studies of AD. Furthermore, quantitative evaluation of beta-amyloid plaques in the brain could allow facilitate the evaluation of the efficacy of anti-amyloid therapies that are currently being investigated. A number of groups have worked to develop radiolabeled amyloid imaging agents, and clinical trials in AD patients have been reported with several agents including [18F]FDDNP, [11C]PIB, [11C]SB-13 and [123I]IMPY, indicating that detecting beta-amyloid plaques in the living human brain with amyloid imaging agents is potentially feasible. More recently, we have reported additional promising compounds such as flavone or chalcone derivatives. The combination of relatively high binding affinity to Abeta and high brain uptake and good clearance in mice of these flavonoid derivatives provides a series of potential amyloid imaging agents for PET and SPECT. In this manuscript, recent progress in amyloid imaging studies is reviewed with the development of amyloid imaging agents.\nGenerate your own set of questions and answers about the above article:\n****\n[Ques]: are beta-amyloid plaques in the brain detectable with molecular imaging?\n[Ans]: Here's my solution: Detection of beta-amyloid plaques in the living human brain with amyloid imaging agents is potentially feasible. The answer is Yes"
cpd_file_path = "data/bio/instruction_biomed_n_gram_probs/cpd.pkl"


cpd = load_object_from_file(cpd_file_path)
tokens = word_tokenize(text.lower())  
token_probs = {}
n = 0

final_tokens = [tokens[0]] 
for i in range(1, len(tokens)):
    
    context = tokens[i-1]
    word = tokens[i]
    prob = cpd[context].prob(word) if context in cpd else 0.0
    token_probs[word] = prob
    if prob < threshold:
        prob_dist = cpd[context]
        possible_words = list(prob_dist.samples())  
        possible_words_sorted = sorted(possible_words, key=lambda w: prob_dist.prob(w), reverse=True)
        
        accept_token = reject_sampling(possible_words_sorted)
        
        # top_predictions = [(w, prob_dist.prob(w)) for w in possible_words_sorted[:64]]
        n += 1
        # print(f"Predictions for context '{tokens[i-1]}', golden token '{word}': {top_predictions}" + "\n\n\n")
        final_tokens.append(accept_token[0])
    else:
        final_tokens.append(word)
            
print(f"revised times : {n}")

revised_str = ' '.join(final_tokens)


tokenizer = AutoTokenizer.from_pretrained("pre_trained_model/HuggingFaceTB/fineweb-edu-classifier")
model = AutoModelForSequenceClassification.from_pretrained("pre_trained_model/HuggingFaceTB/fineweb-edu-classifier")

input_text = [text, revised_str]
inputs = tokenizer(input_text, return_tensors="pt", padding="longest", truncation=True)
outputs = model(**inputs)
logits = outputs.logits.squeeze(-1).float().detach().numpy()

sorces = [int(round(max(0, min(score, 5)))) for score in logits.tolist()]

# score = logits.item()
# result = {
#     "text": text,
#     "score": score,
#     "int_score": int(round(max(0, min(score, 5)))),
# }

print(sorces)